{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5163436-fcca-4ae4-8eaf-6755790380e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run only once\n",
    "# !pip install ddgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dabf75",
   "metadata": {},
   "source": [
    "## How to search for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a87803-eb5a-4e72-9724-e86b268b1a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddgs import DDGS\n",
    "\n",
    "def search_images(keyword, max_results=100):\n",
    "    with DDGS() as ddgs:\n",
    "        images = ddgs.images(\n",
    "            keyword,\n",
    "            max_results=max_results\n",
    "        )\n",
    "        return [img['image'] for img in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e486a04c",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "\n",
    "Note we got less images than we asked for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77f11575-f03b-4a7f-9144-6e11cc5347df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword = \"banana\"\n",
    "image_urls = search_images(keyword, max_results=500)\n",
    "len(image_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52daecb0",
   "metadata": {},
   "source": [
    "Let us take a random image and look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01aaa328-6d23-4792-976a-e379ad047afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://blwstore.com/wp-content/uploads/2022/12/How-to-offer-Banana-in-BLW.jpg'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_urls[90]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50913807",
   "metadata": {},
   "source": [
    "### Bulk Image Search Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d88eece4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pears: 400\n",
      "https://images6.alphacoders.com/677/thumb-1920-677397.jpg\n",
      "https://wallpapershome.com/images/wallpapers/pear-2160x3840-rain-25695.jpg\n",
      "https://gardenerspath.com/wp-content/uploads/2023/08/Asian-Pears-Growing-in-the-Garden.jpg\n",
      "https://as1.ftcdn.net/v2/jpg/01/39/83/96/1000_F_139839656_gJAU0DX9s9t9DIdQ1YWBzUpkv8zcXZS4.jpg\n",
      "https://thumbs.dreamstime.com/z/seamless-pears-background-fully-editable-files-included-51789313.jpg\n",
      "\n",
      "Number of blueberries: 400\n",
      "https://wallpaperaccess.com/full/1466309.jpg\n",
      "https://coolwallpapers.me/picsup/2710639-blueberry-4k-images-background.jpg\n",
      "https://thumbs.dreamstime.com/b/vertical-picture-organic-blueberries-growing-garden-beautiful-summer-scenery-latvia-northern-europe-vertical-picture-340781775.jpg\n",
      "https://thumbs.dreamstime.com/z/blueberry-green-leafs-white-background-blueberries-food-texture-photography-horizontal-format-advertising-photo-ai-296506903.jpg\n",
      "https://thumbs.dreamstime.com/z/illustrated-blueberry-background-tile-seamless-repeating-pattern-backgrounds-blueberries-black-ai-generated-282909013.jpg\n",
      "\n",
      "Number of bananas: 400\n",
      "https://images3.alphacoders.com/658/658611.jpg\n",
      "https://wallpaperaccess.com/full/5317532.jpg\n",
      "https://thumbs.dreamstime.com/z/banana-grove-plantation-trees-ripening-bananas-harvest-coming-soon-vertical-photo-close-up-selective-focus-265430495.jpg\n",
      "https://c8.alamy.com/comp/CPTCFG/loads-of-yellow-bananas-in-a-horizontal-composition-CPTCFG.jpg\n",
      "https://img.freepik.com/free-vector/hand-drawn-lineal-engraved-banana-pattern_23-2149353214.jpg?w=2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import time\n",
    "from typing import List, Iterable, Optional, Set\n",
    "\n",
    "def _query_variations(base: str,\n",
    "                      extra_mods: Optional[Iterable[str]] = None,\n",
    "                      include_defaults: bool = True,\n",
    "                      max_variations: int = 200) -> List[str]:\n",
    "    \"\"\"\n",
    "    Build a list of query variations to bypass the ~100-results cap per query.\n",
    "    You can pass your own `extra_mods`; sensible defaults are included.\n",
    "    \"\"\"\n",
    "    defaults1 = [\n",
    "        \"\", \"close-up\", \"outdoor\", \"indoor\", \"portrait\", \"landscape\", \"macro\",\n",
    "        \"high resolution\", \"aesthetic\", \"minimal\", \"pattern\", \"texture\",\n",
    "        \"vintage\", \"modern\", \"studio\", \"creative\", \"art\", \"drawing\", \"illustration\",\n",
    "    ]\n",
    "    defaults2 = [\"hd\", \"4k\", \"vertical\", \"horizontal\", \"background\", \"wallpaper\", \"stock\"]\n",
    "\n",
    "    mods1 = (defaults1 if include_defaults else []) + list(extra_mods or [])\n",
    "    mods2 = defaults2 if include_defaults else [\"\"]\n",
    "\n",
    "    # build combinations but keep it compact\n",
    "    variations = []\n",
    "    for m1, m2 in itertools.product(mods1, mods2):\n",
    "        q = \" \".join([base, m1, m2]).strip()\n",
    "        if q not in variations:\n",
    "            variations.append(q)\n",
    "        if len(variations) >= max_variations:\n",
    "            break\n",
    "    return variations\n",
    "\n",
    "def search_images_bulk(keyword: str,\n",
    "                       total: int = 500,\n",
    "                       per_query_cap: int = 100,\n",
    "                       extra_modifiers: Optional[Iterable[str]] = None,\n",
    "                       sleep_sec: float = 0.4,\n",
    "                       safe: str = \"moderate\") -> List[str]:\n",
    "    \"\"\"\n",
    "    Collect up to `total` image URLs by running multiple DDG queries.\n",
    "    - `safe`: 'on' | 'moderate' | 'off' (ddgs supports these)\n",
    "    - `extra_modifiers`: iterable of strings appended to form variations\n",
    "    \"\"\"\n",
    "    seen: Set[str] = set()\n",
    "    out: List[str] = []\n",
    "\n",
    "    variations = _query_variations(keyword, extra_modifiers, include_defaults=True)\n",
    "\n",
    "    with DDGS() as ddgs:\n",
    "        for q in variations:\n",
    "            # ddgs.images supports max_results; other filters differ by version.\n",
    "            # Keep it minimal & robust.\n",
    "            try:\n",
    "                results = ddgs.images(q, max_results=min(per_query_cap, 100), safesearch=safe)\n",
    "            except TypeError:\n",
    "                # Older versions may not accept 'safesearch' kwarg\n",
    "                results = ddgs.images(q, max_results=min(per_query_cap, 100))\n",
    "\n",
    "            added_this_round = 0\n",
    "            for r in results:\n",
    "                url = r.get(\"image\") or r.get(\"thumbnail\") or r.get(\"url\")\n",
    "                if not url or url in seen:\n",
    "                    continue\n",
    "                seen.add(url)\n",
    "                out.append(url)\n",
    "                added_this_round += 1\n",
    "                if len(out) >= total:\n",
    "                    return out\n",
    "\n",
    "            # polite pacing (also helps avoid throttling)\n",
    "            time.sleep(sleep_sec)\n",
    "\n",
    "    return out\n",
    "\n",
    "# --- example usage ---\n",
    "# urls = search_images_bulk(\"golden retriever puppies\", total=500,\n",
    "#                           extra_modifiers=[\"running\", \"playing\", \"sleeping\", \"portrait\"])\n",
    "\n",
    "pears = search_images_bulk(\"pear\", total=400)\n",
    "blueberries = search_images_bulk(\"blueberry\", total=400)\n",
    "bananas = search_images_bulk(\"banana\", total=400)\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Number of pears: {len(pears)}\\n\"\n",
    "    f\"{pears[0]}\\n\"\n",
    "    f\"{pears[100]}\\n\"\n",
    "    f\"{pears[200]}\\n\"\n",
    "    f\"{pears[300]}\\n\"\n",
    "    f\"{pears[399]}\\n\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Number of blueberries: {len(blueberries)}\\n\"\n",
    "    f\"{blueberries[0]}\\n\"\n",
    "    f\"{blueberries[100]}\\n\"\n",
    "    f\"{blueberries[200]}\\n\"\n",
    "    f\"{blueberries[300]}\\n\"\n",
    "    f\"{blueberries[399]}\\n\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Number of bananas: {len(bananas)}\\n\"\n",
    "    f\"{bananas[0]}\\n\"\n",
    "    f\"{bananas[100]}\\n\"\n",
    "    f\"{bananas[200]}\\n\"\n",
    "    f\"{bananas[300]}\\n\"\n",
    "    f\"{bananas[399]}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eca2401",
   "metadata": {},
   "source": [
    "## How to download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c95ce62e-2194-48ff-b7db-d15c335fcbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "import warnings\n",
    "\n",
    "def download_image(url, folder, custom_name=None, verbose=True):\n",
    "    # Create the folder if it doesn't exist\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Get the filename from the URL or use the custom name\n",
    "    if custom_name:\n",
    "        filename = custom_name\n",
    "    else:\n",
    "        filename = os.path.basename(urlparse(url).path)\n",
    "        if not filename:\n",
    "            filename = 'image.jpg'  # Default filename if none is found in the URL\n",
    "\n",
    "    # Ensure the filename has an extension\n",
    "    if not os.path.splitext(filename)[1]:\n",
    "        filename += '.jpg'\n",
    "\n",
    "    filepath = os.path.join(folder, filename)\n",
    "\n",
    "    # If the file already exists, append a number to make it unique\n",
    "    base, extension = os.path.splitext(filepath)\n",
    "    counter = 1\n",
    "    while os.path.exists(filepath):\n",
    "        filepath = f\"{base}_{counter}{extension}\"\n",
    "        counter += 1\n",
    "\n",
    "    try:\n",
    "        # Send a GET request to the URL with a timeout of 10 seconds\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()  # Raises an HTTPError for bad responses\n",
    "\n",
    "        # Check if the content type is an image\n",
    "        content_type = response.headers.get('content-type', '')\n",
    "        if not content_type.startswith('image'):\n",
    "            if verbose:\n",
    "                warnings.warn(f\"The URL does not point to an image. Content-Type: {content_type}\")\n",
    "            return False\n",
    "\n",
    "        # Write the image content to the file\n",
    "        with open(filepath, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Image successfully downloaded: {filepath}\")\n",
    "        return True\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        if verbose: \n",
    "            warnings.warn(f\"Download timed out for URL: {url}\")\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if verbose: \n",
    "            warnings.warn(f\"HTTP error occurred: {e}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        if verbose: \n",
    "            warnings.warn(f\"An error occurred while downloading the image: {e}\")\n",
    "    except IOError as e:\n",
    "        if verbose: \n",
    "            warnings.warn(f\"An error occurred while writing the file: {e}\")\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0387ac4b",
   "metadata": {},
   "source": [
    "Let us donwload all teddybears into separate folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91e85251-0074-4c49-9118-03c754a02805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5e6fd8ce474a7b86fc2b7d9987f6aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a009eeaef74f13a3d3e501070f4c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d579bc3c70384407a83438dc09f562ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17b9121057e45628f560debd0794993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84dc513649bb4285a19840d905ca73c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a34dfe0515d457f8e291086b619c306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def download_batch(image_urls, folder, verbose=False):\n",
    "    for i, url in enumerate(tqdm(image_urls)):\n",
    "        download_image(url, folder, f'image {i:03}.jpg', verbose=verbose)\n",
    "\n",
    "download_batch(bananas[:300], \"./dataset/train/banana/\", verbose=False)\n",
    "download_batch(pears[:300], \"./dataset/train/pear/\", verbose=False)\n",
    "download_batch(blueberries[:300], \"./dataset/train/blueberry/\", verbose=False)\n",
    "download_batch(bananas[300:], \"./dataset/test/banana/\", verbose=False)\n",
    "download_batch(pears[300:], \"./dataset/test/pear/\", verbose=False)\n",
    "download_batch(blueberries[300:], \"./dataset/test/blueberry/\", verbose=False)\n",
    "\n",
    "\n",
    "    # download_image(url, \"./dataset/teddybear/\", f'image {i:03}.jpg', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f30d48",
   "metadata": {},
   "source": [
    "## How to resize all images to 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58bba29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 — imports & config\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eec399b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd109021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702 269\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — data loaders\n",
    "mean, std = (0.5,), (0.5,)\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "test_tf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "    transforms.Resize((28, 28)),\n",
    "])\n",
    "\n",
    "\n",
    "train = datasets.ImageFolder(root=\"./dataset/train\", transform=train_tf)\n",
    "test  = datasets.ImageFolder(root=\"./dataset/test\", transform=test_tf)\n",
    "\n",
    "train_loader = DataLoader(train, pin_memory=True)\n",
    "test_loader  = DataLoader(test, pin_memory=True)\n",
    "\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93c83587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BetterCNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1): Dropout(p=0.25, inplace=False)\n",
       "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (drop2): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BetterCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)   # 28x28 -> 28x28, 3 channels for RGB\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 28x28 -> 28x28\n",
    "        self.pool  = nn.MaxPool2d(2, 2)                           # 28->14, 14->7\n",
    "        self.drop1 = nn.Dropout(0.25)\n",
    "        self.fc1   = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "        self.fc2   = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 28->14\n",
    "        x = self.drop1(x)\n",
    "        # add a tiny extra conv block without extra params by reusing conv2? keep small: skip.\n",
    "        x = self.pool(x)                      # 14->7\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop2(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "model = BetterCNN().to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f845cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)  # halve LR every 5 epochs\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c78648c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 — helpers\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss, correct, n = 0.0, 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        correct += (logits.argmax(1) == y).sum().item()\n",
    "        n += y.size(0)\n",
    "    return total_loss / n, correct / n\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, n = 0.0, 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        correct += (logits.argmax(1) == y).sum().item()\n",
    "        n += y.size(0)\n",
    "    return total_loss / n, correct / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b8cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 6 — training loop\n",
    "epochs = 11\n",
    "best_acc = 0.0\n",
    "patience, wait = 4, 0\n",
    "best_state = None\n",
    "start = time()\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    va_loss, va_acc = evaluate(model, test_loader, criterion, device)\n",
    "    scheduler.step()\n",
    "\n",
    "    if va_acc > best_acc:\n",
    "        best_acc, wait = va_acc, 0\n",
    "        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "    else:\n",
    "        wait += 1\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train loss: {tr_loss:.4f}, accuracy: {tr_acc * 100:.2f}% \"\n",
    "          f\"| test loss: {va_loss:.4f}, accuracy: {va_acc * 100:.2f}%\")\n",
    "\n",
    "    if wait >= patience:\n",
    "        print(\"Early stopping.\")\n",
    "        break\n",
    "\n",
    "print(f\"Done in {(time()-start):.1f}s. Best test acc: {best_acc:.3f}\")\n",
    "if best_state is not None:\n",
    "    model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7fb9ef5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test:\n",
      "loss: 12.3547\n",
      "accuracy: 33.09%\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 — final metrics\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"Final test:\\n\"\n",
    "      f\"loss: {test_loss:.4f}\\n\"\n",
    "      f\"accuracy: {test_acc * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
